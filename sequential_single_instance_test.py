#!/usr/bin/env python3
"""
Sequential Single Instance Test Script for Mannequin Segmenter API
Sends 50 random pulover images sequentially (one after another) to a single VM instance
to analyze response time variations without any concurrency
"""

import asyncio
import aiohttp
import time
import statistics
from datetime import datetime
import json
import random
import os

# ========== KONFIGUR√ÅCI√ìS PARAM√âTEREK ==========
TARGET_INSTANCE = "http://35.233.66.133:5001"  # Tesztelend≈ë VM instance
TOTAL_REQUESTS = 50                             # √ñsszes k√©r√©sek sz√°ma
REQUEST_TIMEOUT = 120                           # Timeout m√°sodpercben (hosszabb a stabilit√°s√©rt)
URL_LIST_FILE = "pulover_urls.txt"              # Pulover URL-ek f√°jlja
DELAY_BETWEEN_REQUESTS = 0.5                    # Kis sz√ºnet k√©r√©sek k√∂z√∂tt (m√°sodperc)

# API endpoint
API_ENDPOINT = "/infer"

# ===============================================

def load_urls_from_file(filename):
    """URL-ek bet√∂lt√©se f√°jlb√≥l"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip()]
        print(f"üìÇ URL-ek bet√∂ltve: {filename} ({len(urls)} darab)")
        return urls
    except Exception as e:
        print(f"‚ùå Hiba a f√°jl olvas√°sakor: {e}")
        return []

class SequentialTester:
    def __init__(self, image_urls, target_instance):
        self.image_urls = image_urls
        self.target_instance = target_instance
        self.results = []
        self.errors = []
        
        # Random kiv√°laszt√°s √©s kever√©s
        if len(image_urls) >= TOTAL_REQUESTS:
            self.test_urls = random.sample(image_urls, TOTAL_REQUESTS)
        else:
            self.test_urls = image_urls
            print(f"‚ö†Ô∏è  Csak {len(image_urls)} URL el√©rhet≈ë, az √∂sszeset haszn√°ljuk")
        
        # Kever√©s a random sorrend√©rt
        random.shuffle(self.test_urls)
        
        print(f"üéØ {len(self.test_urls)} random pulover k√©p kiv√°lasztva szekvenci√°lis teszthez")
    
    async def make_single_request(self, session, request_id, image_url):
        """Egyetlen API k√©r√©s v√©grehajt√°sa"""
        full_url = f"{self.target_instance}{API_ENDPOINT}"
        request_start = time.time()
        
        # URL r√∂vid megjelen√≠t√©se
        short_url = image_url.split('/')[-1][:50] + "..." if len(image_url.split('/')[-1]) > 50 else image_url.split('/')[-1]
        
        print(f"üîÑ Request {request_id:2d}/50: {short_url}", end="", flush=True)
        
        try:
            payload = {
                "image_url": image_url,
                "prompt_mode": "both"
            }
            
            async with session.post(
                full_url,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
            ) as response:
                response_text = await response.text()
                request_end = time.time()
                response_time = request_end - request_start
                
                result = {
                    "request_id": request_id,
                    "image_url": image_url,
                    "status_code": response.status,
                    "response_time": response_time,
                    "timestamp": datetime.fromtimestamp(request_start),
                    "success": response.status == 200,
                    "response_size": len(response_text)
                }
                
                if response.status == 200:
                    try:
                        json_response = json.loads(response_text)
                        result["has_visualization_url"] = "visualization_url" in json_response
                        if "timing" in json_response:
                            result["server_timing"] = json_response["timing"]
                            # Server-side timing r√©szletez√©se
                            timing = json_response["timing"]
                            if "model_inference" in timing and "gcs_total" in timing:
                                result["server_model_inference"] = timing["model_inference"]
                                result["server_gcs_total"] = timing["gcs_total"]
                                result["server_total_request"] = timing.get("total_request", 0)
                    except json.JSONDecodeError:
                        result["has_visualization_url"] = False
                
                self.results.append(result)
                
                # R√©szletes kimenet
                status_icon = "‚úÖ" if response.status == 200 else "‚ùå"
                server_info = ""
                if "server_timing" in result:
                    model_time = result.get("server_model_inference", 0)
                    gcs_time = result.get("server_gcs_total", 0)
                    server_info = f" (model: {model_time:.2f}s, gcs: {gcs_time:.2f}s)"
                
                print(f" {status_icon} {response.status} ({response_time:.3f}s{server_info})")
                
        except asyncio.TimeoutError:
            request_end = time.time()
            response_time = request_end - request_start
            error = {
                "request_id": request_id,
                "image_url": image_url,
                "error": "Timeout",
                "response_time": response_time,
                "timestamp": datetime.fromtimestamp(request_start)
            }
            self.errors.append(error)
            print(f" ‚è∞ TIMEOUT ({response_time:.3f}s)")
            
        except Exception as e:
            request_end = time.time()
            response_time = request_end - request_start
            error = {
                "request_id": request_id,
                "image_url": image_url,
                "error": str(e),
                "response_time": response_time,
                "timestamp": datetime.fromtimestamp(request_start)
            }
            self.errors.append(error)
            print(f" ‚ùå ERROR: {e}")
    
    async def run_sequential_test(self):
        """Szekvenci√°lis teszt futtat√°sa"""
        print(f"üöÄ Sequential Single Instance Test")
        print(f"üìä Konfigur√°ci√≥:")
        print(f"   - Target instance: {self.target_instance}")
        print(f"   - K√©r√©sek sz√°ma: {len(self.test_urls)}")
        print(f"   - Request timeout: {REQUEST_TIMEOUT}s")
        print(f"   - K√©r√©sek k√∂z√∂tti sz√ºnet: {DELAY_BETWEEN_REQUESTS}s")
        print(f"   - M√≥d: SZEKVENCI√ÅLIS (egy k√©r√©s egyszerre)")
        print()
        
        start_time = time.time()
        
        async with aiohttp.ClientSession() as session:
            for i, url in enumerate(self.test_urls, 1):
                await self.make_single_request(session, i, url)
                
                # Kis sz√ºnet a k√∂vetkez≈ë k√©r√©s el≈ëtt (kiv√©ve az utols√≥ ut√°n)
                if i < len(self.test_urls):
                    await asyncio.sleep(DELAY_BETWEEN_REQUESTS)
                
                # Progress minden 10. k√©r√©sn√©l
                if i % 10 == 0 or i == len(self.test_urls):
                    elapsed = time.time() - start_time
                    successful = len([r for r in self.results if r["success"]])
                    print(f"üìä Progress: {i}/{len(self.test_urls)} k√©r√©s, {successful} sikeres ({elapsed:.1f}s)")
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\n‚è±Ô∏è  Teszt befejezve! (√∂sszes id≈ë: {total_time:.2f}s)")
        self.print_detailed_statistics()
    
    def print_detailed_statistics(self):
        """R√©szletes statisztik√°k ki√≠r√°sa"""
        successful_requests = [r for r in self.results if r["success"]]
        failed_requests = len(self.results) - len(successful_requests)
        total_requests = len(self.results) + len(self.errors)
        
        print(f"\nüìà R√âSZLETES TESZT EREDM√âNYEK - SZEKVENCI√ÅLIS")
        print(f"=" * 70)
        print(f"üéØ Target Instance: {self.target_instance}")
        print(f"üìä √ñsszes k√©r√©s: {total_requests}")
        print(f"‚úÖ Sikeres k√©r√©sek: {len(successful_requests)}")
        print(f"‚ùå Sikertelen k√©r√©sek: {failed_requests + len(self.errors)}")
        if total_requests > 0:
            print(f"üìà Sikeress√©g ar√°ny: {len(successful_requests)/total_requests*100:.1f}%")
        
        if successful_requests:
            response_times = [r["response_time"] for r in successful_requests]
            
            print(f"\n‚è∞ V√ÅLASZID≈ê STATISZTIK√ÅK")
            print(f"   üîπ Minimum: {min(response_times):.3f} m√°sodperc")
            print(f"   üîπ Maximum: {max(response_times):.3f} m√°sodperc")
            print(f"   üîπ √Åtlag: {statistics.mean(response_times):.3f} m√°sodperc")
            print(f"   üîπ Medi√°n: {statistics.median(response_times):.3f} m√°sodperc")
            if len(response_times) > 1:
                print(f"   üîπ Sz√≥r√°s: {statistics.stdev(response_times):.3f} m√°sodperc")
            
            # Server-side timing statisztik√°k ha el√©rhet≈ëk
            model_times = [r.get("server_model_inference", 0) for r in successful_requests if "server_model_inference" in r]
            gcs_times = [r.get("server_gcs_total", 0) for r in successful_requests if "server_gcs_total" in r]
            
            if model_times:
                print(f"\nü§ñ SERVER-SIDE MODEL INFERENCE STATISZTIK√ÅK")
                print(f"   üîπ Minimum: {min(model_times):.3f} m√°sodperc")
                print(f"   üîπ Maximum: {max(model_times):.3f} m√°sodperc")
                print(f"   üîπ √Åtlag: {statistics.mean(model_times):.3f} m√°sodperc")
                print(f"   üîπ Medi√°n: {statistics.median(model_times):.3f} m√°sodperc")
            
            if gcs_times:
                print(f"\n‚òÅÔ∏è  SERVER-SIDE GCS STATISZTIK√ÅK")
                print(f"   üîπ Minimum: {min(gcs_times):.3f} m√°sodperc")
                print(f"   üîπ Maximum: {max(gcs_times):.3f} m√°sodperc")
                print(f"   üîπ √Åtlag: {statistics.mean(gcs_times):.3f} m√°sodperc")
                print(f"   üîπ Medi√°n: {statistics.median(gcs_times):.3f} m√°sodperc")
            
            # Teljes√≠tm√©ny trend elemz√©s
            if len(response_times) >= 10:
                print(f"\nüìä TELJES√çTM√âNY TREND ELEMZ√âS")
                first_10 = response_times[:10]
                last_10 = response_times[-10:]
                middle_section = response_times[10:-10] if len(response_times) > 20 else []
                
                print(f"   üîπ Els≈ë 10 k√©r√©s √°tlag: {statistics.mean(first_10):.3f}s")
                if middle_section:
                    print(f"   üîπ K√∂z√©ps≈ë r√©sz √°tlag: {statistics.mean(middle_section):.3f}s")
                print(f"   üîπ Utols√≥ 10 k√©r√©s √°tlag: {statistics.mean(last_10):.3f}s")
                
                # Trend ki√©rt√©kel√©s
                first_avg = statistics.mean(first_10)
                last_avg = statistics.mean(last_10)
                
                if last_avg > first_avg * 1.1:
                    print(f"   ‚ö†Ô∏è  Teljes√≠tm√©ny roml√°s √©szlelve (+{((last_avg/first_avg-1)*100):.1f}%)")
                elif last_avg < first_avg * 0.9:
                    print(f"   ‚úÖ Teljes√≠tm√©ny javul√°s √©szlelve (-{((1-last_avg/first_avg)*100):.1f}%)")
                else:
                    print(f"   üìä Stabil teljes√≠tm√©ny (v√°ltoz√°s: {((last_avg/first_avg-1)*100):+.1f}%)")
            
            # Outlier elemz√©s
            print(f"\nüîç OUTLIER ELEMZ√âS")
            avg_time = statistics.mean(response_times)
            std_time = statistics.stdev(response_times) if len(response_times) > 1 else 0
            threshold = avg_time + 2 * std_time
            
            outliers = [(i+1, r) for i, r in enumerate(successful_requests) if r["response_time"] > threshold]
            
            if outliers:
                print(f"   ‚ö†Ô∏è  {len(outliers)} outlier tal√°lva (>{threshold:.3f}s):")
                for req_num, outlier in outliers[:5]:  # Els≈ë 5 outlier
                    short_url = outlier["image_url"].split('/')[-1][:40]
                    print(f"      {req_num:2d}. {outlier['response_time']:6.3f}s - {short_url}")
                if len(outliers) > 5:
                    print(f"      ... √©s m√©g {len(outliers) - 5} darab")
            else:
                print(f"   ‚úÖ Nincs jelent≈ës outlier (k√ºsz√∂b: {threshold:.3f}s)")
        
        # Hib√°k r√©szletez√©se
        if self.errors:
            print(f"\n‚ùå HIB√ÅK R√âSZLETEZ√âSE")
            error_types = {}
            for error in self.errors:
                error_type = error["error"]
                if error_type not in error_types:
                    error_types[error_type] = 0
                error_types[error_type] += 1
            
            for error_type, count in error_types.items():
                print(f"   üîπ {error_type}: {count} alkalom")
        
        # √ñsszes k√©r√©s list√°ja
        print(f"\nüìã √ñSSZES K√âR√âS R√âSZLETESEN")
        print(f"{'#':<3} {'Id≈ëb√©lyeg':<12} {'V√°laszid≈ë':<10} {'Model':<8} {'GCS':<6} {'St√°tusz':<7} {'K√©p':<40}")
        print(f"{'-'*3} {'-'*12} {'-'*10} {'-'*8} {'-'*6} {'-'*7} {'-'*40}")
        
        for i, result in enumerate(self.results, 1):
            timestamp_str = result["timestamp"].strftime("%H:%M:%S")
            model_time = result.get("server_model_inference", 0)
            gcs_time = result.get("server_gcs_total", 0)
            status = "‚úÖ 200" if result["success"] else f"‚ùå {result['status_code']}"
            short_url = result["image_url"].split('/')[-1][:35]
            
            print(f"{i:<3} {timestamp_str:<12} {result['response_time']:8.3f}s {model_time:6.3f}s {gcs_time:4.3f}s {status:<7} {short_url:<40}")
        
        # Hib√°s k√©r√©sek
        for i, error in enumerate(self.errors, len(self.results) + 1):
            timestamp_str = error["timestamp"].strftime("%H:%M:%S")
            short_url = error["image_url"].split('/')[-1][:35]
            print(f"{i:<3} {timestamp_str:<12} {error['response_time']:8.3f}s {'N/A':>6} {'N/A':>4} ‚ùå ERR {short_url:<40}")

async def main():
    """F≈ë program bel√©p√©si pont"""
    print("üîß Sequential Single Instance Performance Test")
    print("=" * 60)
    
    # URL-ek bet√∂lt√©se
    if not os.path.exists(URL_LIST_FILE):
        print(f"‚ùå URL f√°jl nem tal√°lhat√≥: {URL_LIST_FILE}")
        print("üí° Futtasd el≈ëbb az improved_dynamic_load_balancer.py-t hogy gener√°lja a URL-eket")
        return
    
    image_urls = load_urls_from_file(URL_LIST_FILE)
    if not image_urls:
        print("‚ùå Nem siker√ºlt URL-eket bet√∂lteni")
        return
    
    print(f"üéØ {len(image_urls)} pulover k√©p el√©rhet≈ë")
    
    # Teszter l√©trehoz√°sa √©s futtat√°sa
    tester = SequentialTester(image_urls, TARGET_INSTANCE)
    await tester.run_sequential_test()

if __name__ == "__main__":
    asyncio.run(main())
